{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Tuple, Optional, Any\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "# torch.set_num_threads(cpu_count() - 1)\n",
    "torch.set_num_threads(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "with open('names.txt', 'r') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "vocab = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i for i,s in enumerate(vocab, start=1)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val, test split\n",
    "random.shuffle(words)\n",
    "\n",
    "train_split = .8; val_split = .1\n",
    "\n",
    "n1 = int(train_split * len(words))\n",
    "n2 = int((train_split + val_split) * len(words))\n",
    "\n",
    "X_train, Y_train = build_dataset(words[:n1])\n",
    "X_val, Y_val = build_dataset(words[n1:n2])\n",
    "X_test, Y_test = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility fn to compare gradients calc manually v/s via PyTorch\n",
    "def cmp(s, dt: torch.Tensor, t: torch.Tensor):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "#IMP FOR THIS NOTEBOOK: CHANGE SOME INIT VALUES AS ZEROS MAY MASK SOME INCORRECT GRADIENT IMPL, **JUST FOR LEARNING PURPOSES**\n",
    "\n",
    "# build MLP\n",
    "\n",
    "# MLP structure params\n",
    "emb_dim_size = 10\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# MLP params\n",
    "C = torch.randn((vocab_size, emb_dim_size), generator=g).float() # represent each character in dim space\n",
    "#Layer 1\n",
    "W1 = torch.randn((block_size * emb_dim_size, hidden_layer_size), generator=g).float() # weights for hidden layer, for each neuron, it will receive block_size number of i/p, each i/p of dimension dim_size\n",
    "W1 = W1 * (5/3) / ((block_size * emb_dim_size) ** 0.5) # kiming_init - to \"fight the contraction of tanh\", preserve gaussian std. -> to resolve tanh saturation\n",
    "b1 = torch.randn(hidden_layer_size, generator=g).float() # each neuron will have 1-D bias # USING BIAS JUST FOR FUN\n",
    "b1 = b1 * 0.1 # normally: 0.001 # to resolve tanh saturation\n",
    "# Layer 2\n",
    "W2 = torch.randn((hidden_layer_size, vocab_size), generator=g).float() # weights for output layer, each neuron of hidden layer fully connected to each neuron of output layer\n",
    "W2 = W2 * 0.1 # to normalize loss at initialization\n",
    "b2 = torch.randn(vocab_size, generator=g).float() # num_neurons in output layer equal to vocab size, to represent probs for each character\n",
    "b2 = b2 * 0.1 # normally 0 # to normalize loss at initialization\n",
    "\n",
    "## batch norm params: want the distribution to be more flexible, not constrict it to be always Gaussian, just need at initialization.\n",
    "# batch_norm_gain = torch.ones((1, hidden_layer_size))\n",
    "# batch_norm_bias = torch.zeros((1, hidden_layer_size))\n",
    "# change from normal, normal above\n",
    "batch_norm_gain = torch.randn((1, hidden_layer_size)) * 0.1 + 1.0\n",
    "batch_norm_bias = torch.randn((1, hidden_layer_size)) * 0.1\n",
    "\n",
    "params = [C, W1, b1, W2, b2, batch_norm_gain, batch_norm_bias]\n",
    "\n",
    "running_mean = torch.zeros((1, hidden_layer_size))\n",
    "running_std = torch.ones((1, hidden_layer_size))\n",
    "\n",
    "print(sum(p.nelement() for p in params))\n",
    "\n",
    "for p in params:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "n = batch_size\n",
    "# construct minibatch\n",
    "ix = torch.randint(0, X_train.shape[0], (n, ), generator=g)\n",
    "Xb, Yb = X_train[ix], Y_train[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6580, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FORWARD PASS: CHUNKED INTO SIMPLE, MANAGEABLE STEPS THAT CAN BE BACKPROP'ED ONE AT A TIME\n",
    "\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "# -----------Linear layer 1---------------\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "# ----------BatchNorm layer---------------\n",
    "bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = (\n",
    "    1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    ")  # Bessel's correction, dividing by (n-1) not n, for mean calc\n",
    "with torch.no_grad():\n",
    "    epsilon = 1e-5\n",
    "bnvar_inv = (bnvar + epsilon) ** -0.5  # inverse of \"bnstd\"\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "# ----------Non-linearity---------------\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2\n",
    "# cross-entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes  # subtract max for numerical stability ??\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# Pytorch backward pass\n",
    "for p in params:\n",
    "    p.grad = None\n",
    "\n",
    "\n",
    "gradvars = [\n",
    "    logprobs,\n",
    "    probs,\n",
    "    counts,\n",
    "    counts_sum,\n",
    "    counts_sum_inv,\n",
    "    norm_logits,\n",
    "    logit_maxes,\n",
    "    logits,\n",
    "    h,\n",
    "    hpreact,\n",
    "    bnraw,\n",
    "    bnvar_inv,\n",
    "    bnvar,\n",
    "    bndiff2,\n",
    "    bndiff,\n",
    "    hprebn,\n",
    "    bnmeani,\n",
    "    embcat,\n",
    "    emb\n",
    "]\n",
    "\n",
    "for t in gradvars:\n",
    "    t.retain_grad()\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprob         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dcounts_sum_inv | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dcounts_sum     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dcounts         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dnorm_logits    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogit_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dlogits         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dh              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dW2             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "db2             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "dhpreact        | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dbatch_norm_gain | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "dbatch_norm_bias | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "dbnraw          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "dbnvar_inv      | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "dbnvar          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n",
      "dbndiff2        | exact: False | approximate: True  | maxdiff: 4.3655745685100555e-11\n",
      "dbndiff         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dbnmeani        | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "dhprebn         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "dembcat         | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
      "dW1             | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
      "db1             | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "demb            | exact: False | approximate: True  | maxdiff: 1.3969838619232178e-09\n",
      "dC              | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n"
     ]
    }
   ],
   "source": [
    "#backprop through the grads array manually\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n # loss = -dlogprobs[range(n), Yb].mean() => loss = -(a + b + c) / 3 => dloss/da = -1/3 n = 32 in our case (batch size)\n",
    "\n",
    "dprobs = 1.0/probs # logprobs = probs.log() => log(a) => dlogprobs/da = 1/a\n",
    "dprobs = dprobs * dlogprobs # chain rule\n",
    "\n",
    "# c = a * b\n",
    "# tensor\n",
    "# c[3x3] = a[3x3] * b[3x1]\n",
    "# c1 = a11*b1  a12*b1  a13*b1\n",
    "# c2 = a21*b2  a22*b2  a23*b2\n",
    "# c3 = a31*b1  a32*b2  a33*b3\n",
    "\n",
    "dcounts_sum_inv = counts # probs = counts * counts_sum_inv => probs = b * a, dprobs/da = b\n",
    "dcounts_sum_inv = dcounts_sum_inv * dprobs # chain rule\n",
    "dcounts_sum_inv = dcounts_sum_inv.sum(1, keepdim=True) # sum through pytorch replication => m1 [3X1] => m2 [3x3] so gradients would be summed across rows\n",
    "# dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "\n",
    "# dcounts --- 1st contribution (from probs)\n",
    "dcounts = counts_sum_inv # probs = counts * counts_sum_inv => probs = b * a, dprobs/db = a\n",
    "dcounts = dcounts * dprobs # chain rule #TODO: Investigate why dcounts *= dprobs doesn't work here. Look at shapes for hint.\n",
    "\n",
    "dcounts_sum = (-counts_sum ** -2)# counts_sum_inv = counts_sum ** -1, y = x**-1, dy/dx = -x**-2\n",
    "dcounts_sum = dcounts_sum * dcounts_sum_inv # chain rule\n",
    "\n",
    "# dcounts --- 2nd contribution (from counts_sum)\n",
    "# a[3x3] -> b[3x1] (rows summed)\n",
    "# a11 a12 a13   b1 = a11 + a12 + a13\n",
    "# a21 a22 a23   b2 = a21 + a22 + a23\n",
    "# a31 a32 a33   b3 = a31 + a32 + a33\n",
    "\n",
    "# db/da = [1 1 1] (3x1)\n",
    "\n",
    "dcounts = dcounts + (torch.ones(counts.shape) * dcounts_sum)\n",
    "\n",
    "# dnorm_logits\n",
    "# counts = norm_logits.exp() # both of same shape\n",
    "# y = e ** x\n",
    "# dy/dx = e ** x = y\n",
    "dnorm_logits = counts * dcounts # chain rule\n",
    "\n",
    "# dlogit_maxes\n",
    "# norm_logits = logits - logit_maxes\n",
    "# y = a - x\n",
    "# dy/dx = -1\n",
    "# however, norm_logits.shape = [n, vocab_size], logit_maxes.shape = [n, 1]\n",
    "# so, need to do backprop for broadcasting(replication) as well, sum across rows\n",
    "dlogit_maxes = -(torch.ones_like(logit_maxes) * dnorm_logits).sum(1, keepdim=True)\n",
    "\n",
    "# dlogits\n",
    "# contribution 1\n",
    "# norm_logits = logits - logit_maxes\n",
    "# y = x - a\n",
    "# dy/dx = 1\n",
    "dlogits = torch.ones_like(logits) * dnorm_logits # this will make approximate=True but not exact\n",
    "\n",
    "# contribution 2\n",
    "# logit_maxes = logits.max(1, keepdim=True)\n",
    "# so dlogit_maxes/dlogits = 0 for non-max elements in logits and 1 for the max element\n",
    "# start with torch.zeros and then make the max elements 1\n",
    "# clean way -> (logits == logit_maxes).float() -> will be 1 for max elements and 0 otherwise\n",
    "dlogits = dlogits + ((logits == logit_maxes).float()) * dlogit_maxes\n",
    "\n",
    "# dh\n",
    "# logits = h @ W2 + b2\n",
    "# shapes: W2 = [n_hidden, vocab_size], h = [n, n_hidden], logits = [n, vocab_size]\n",
    "# dlogits/dh comes out to be upstream gradient (dlogits) @ transpose of W2\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "dh = dlogits @ W2.T\n",
    "\n",
    "#dW2\n",
    "# logits = h @ W2 + b2\n",
    "# shapes: W2 = [n_hidden, vocab_size], h = [n, n_hidden], logits = [n, vocab_size]\n",
    "# dlogits/dW2 comes out to be transpose of upstream gradient(dlogits.T) @ h\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "dW2 = (dlogits.T @ h).T\n",
    "\n",
    "#db2\n",
    "# logits = h @ W2 + b2\n",
    "# shapes: W2 = [n_hidden, vocab_size], h = [n, n_hidden], logits = [n, vocab_size]\n",
    "# dlogits/db2 comes to be sum of dlogits summed over the columns\n",
    "# it can also be written as the matmul of dlogits.T and the ones column vector of shape dlogits\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "#db2 = (dlogits.T @ torch.ones((dlogits.shape[0],1))).squeeze() # approximate = True, exact = False, possibly due to matmuls and float errors, mathematically same as below\n",
    "db2 = dlogits.sum(0)\n",
    "\n",
    "# hpreact\n",
    "# h = torch.tanh(hpreact)\n",
    "# shapes: same\n",
    "# y = tanh(x), dy/dx = 1-(tanh(x) ** 2) = 1-y**2\n",
    "dhpreact = (1.0-h**2) * dh # approximate = True, exact = False\n",
    "\n",
    "# dbatch_norm_gain\n",
    "# hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "# shapes: hpreact: [n, n_hidden], bnraw: [n, n_hidden], batch_norm_gain: [1, n_hidden], batch_norm_bias: [1, n_hidden]\n",
    "# y = a * x + b\n",
    "# dy/dx = a\n",
    "# batch_norm_gain is broadcasted to [n, n_hidden] and then element-wise multiplied with bnraw\n",
    "# so, need to sum over rows for dbatch_norm_gain\n",
    "dbatch_norm_gain = (bnraw * dhpreact).sum(0, keepdim=True) # approximate = True, exact = False\n",
    "\n",
    "# dbatch_norm_bias\n",
    "# hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "# shapes: hpreact: [n, n_hidden], bnraw: [n, n_hidden], batch_norm_gain: [1, n_hidden], batch_norm_bias: [1, n_hidden]\n",
    "# y = a * x + b\n",
    "# dy/db = 1\n",
    "# batch_norm_bias is broadcasted to [n, n_hidden] and then element-wise added to bnraw * batch_norm_gain\n",
    "# so, need to sum over rows for dbatch_norm_bias\n",
    "dbatch_norm_bias = dhpreact.sum(0, keepdim=True)\n",
    "\n",
    "# dbnraw\n",
    "# hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "# shapes: same\n",
    "# y = a * x + b\n",
    "# dy/da = x\n",
    "# no need for broadcasting as bnraw and dhpreact have same shape\n",
    "dbnraw = batch_norm_gain * dhpreact\n",
    "\n",
    "# dbndiff\n",
    "# contribution 1 --- from bnraw\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# shapes: bnraw: [n, n_hidden], bndiff: [n, n_hidden], bnvar_inv: [1, n_hidden]\n",
    "# y = x * a\n",
    "# dy/dx = a\n",
    "# no need for broadcasting as bnraw and bndiff have same shape\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "\n",
    "# dbnvar_inv\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# shapes: bnraw: [n, n_hidden], bndiff: [n, n_hidden], bnvar_inv: [1, n_hidden]\n",
    "# y = x * a\n",
    "# dy/da = x\n",
    "# bnvar_inv is broadcasted to [n, n_hidden] and then element-wise multiplied to bndiff\n",
    "# so, need to sum over rows for dbnvar_inv\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "\n",
    "# dbnvar\n",
    "# bnvar_inv = (bnvar + epsilon) ** -0.5\n",
    "# shapes: [1, n_hidden], same\n",
    "# y = (x + a)**-0.5\n",
    "# dy/dx = (-0.5(x + a)**-1.5) * (d (x + a) /dx) => -0.5 (x + a)**-1.5 => -0.5 y**3\n",
    "dbnvar = (-0.5 * bnvar_inv ** 3) * dbnvar_inv\n",
    "\n",
    "# dbndiff2\n",
    "# bnvar = (\n",
    "#    1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    "#)\n",
    "# shapes: bnvar: [1, n_hidden], bndiff2: [n, n_hidden]\n",
    "# dy/dx = 1/(n-1) * torch.ones_like(bndiff2) (since for each element in bndiff2, grad will be 1)\n",
    "dbndiff2 = ((1.0 / (n-1)) * torch.ones_like(bndiff2)) * dbnvar\n",
    "\n",
    "# dbndiff\n",
    "# contribution 2 --- from bndiff2\n",
    "# bndiff2 = bndiff**2\n",
    "# shapes: same: [n, n_hidden]\n",
    "# y = x ** 2\n",
    "# dy/dx = 2 * x + prev_grad\n",
    "dbndiff += ((2.0 * bndiff) * dbndiff2)\n",
    "\n",
    "# dhprebn\n",
    "# contribution 1 --- from bndiff\n",
    "# bndiff = hprebn - bnmeani\n",
    "# shapes: bndiff: [n, n_hidden], hprebn: [n, n_hidden], bnmeani: [1, n_hidden]\n",
    "# y = x - a\n",
    "# dy/dx = 1 (torch.ones_like(hprebn))\n",
    "# no need for broadcasting as hprebn and bndiff have same shape\n",
    "dhprebn = dbndiff.clone()\n",
    "\n",
    "# dbnmeani\n",
    "# bndiff = hprebn - bnmeani\n",
    "# shapes: bndiff: [n, n_hidden], hprebn: [n_hidden], bnmeani: [1, n_hidden]\n",
    "# y = x - a\n",
    "# dy/da = -1 -(torch.ones_like(bnmeani))\n",
    "# need to sum over dbnmeani, due to row-wise replication\n",
    "dbnmeani = (- 1.0 * (dbndiff)).sum(0, keepdim=True)\n",
    "\n",
    "# dhprebn\n",
    "# contribution 2 --- from bnmeani\n",
    "# bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "# bnmeani: [1, n_hidden], hprebn: [n, n_hidden]\n",
    "# dy/dx = 1/(n) * torch.ones_like(hprebn) + prev_grad (since for each element in hprebn, grad will be 1) + prev_grad\n",
    "dhprebn += ((1.0 / n) * torch.ones_like(hprebn)) * dbnmeani\n",
    "\n",
    "# dembcat\n",
    "# hprebn = embcat @ W1 + b1\n",
    "# shapes: hprebn: [n, n_hidden], embcat: [n, block_size * dim_size], W1: [block_size * dim_size, n_hidden], b1: [n_hidden]\n",
    "# d = a@b+c\n",
    "# dy/da = upstream_grad @ b.T\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "dembcat = dhprebn @ W1.T\n",
    "\n",
    "# dW1\n",
    "# hprebn = embcat @ W1 + b1\n",
    "# shapes: hprebn: [n, n_hidden], embcat: [n, block_size * dim_size], W1: [block_size * dim_size, n_hidden], b1: [n_hidden]\n",
    "# d = a@b+c\n",
    "# dy/db = a.T @ upstream_grad\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "dW1 = embcat.T @ dhprebn\n",
    "\n",
    "# db1\n",
    "# hprebn = embcat @ W1 + b1\n",
    "# shapes: hprebn: [n, n_hidden], embcat: [n, block_size * dim_size], W1: [block_size * dim_size, n_hidden], b1: [n_hidden]\n",
    "# d = a@b+c\n",
    "# dy/dc = upstream_grad row_wise column element sum\n",
    "# check appendix complete handwritten impl. (navigate using below cell)\n",
    "db1 = dhprebn.sum(0, keepdim=True)\n",
    "\n",
    "# demb\n",
    "# embcat = emb.view(emb.shape[0], -1)\n",
    "# shapes: embcat: [n, block_size * dim_size], emb: [n, dim_size, block_size]\n",
    "# dy/dx: just a dim change is occurring, so backprop would be to flatten the view back to original dimensions.\n",
    "demb = dembcat.view_as(emb)\n",
    "\n",
    "#dC\n",
    "# emb = C[Xb]\n",
    "# shapes: emb: [n, block_size, dim_size], C: [vocab_size, dim_size], Xb: [n, block_size]\n",
    "# In forward pass, what's happening for each 3-dim example in Xb (the integer encoding of the character blocks), the corresponding dimension (from C) is fetched and organized into emb.\n",
    "# So to generate dC, we need to get the vocab's corresponding gradient that's sitting in demb and add it to dc\n",
    "# But we need to accumulate gradients as one vocab letter may be used in multiple examples in Xb, and therefore emb.\n",
    "# so dC will be a tensor of zeros of shape like C, but at the indices of Xb, the value will be 1\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "            ix = Xb[k, j]\n",
    "            dC[ix] += demb[k, j]\n",
    "\n",
    "\n",
    "# All comparisons\n",
    "cmp('logprob', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('dcounts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('dcounts_sum', dcounts_sum, counts_sum)\n",
    "cmp('dcounts', dcounts, counts)\n",
    "cmp('dnorm_logits', dnorm_logits, norm_logits)\n",
    "cmp('dlogit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('dlogits', dlogits, logits)\n",
    "cmp('dh', dh, h)\n",
    "cmp('dW2', dW2, W2)\n",
    "cmp('db2', db2, b2)\n",
    "cmp('dhpreact', dhpreact, hpreact)\n",
    "cmp('dbatch_norm_gain', dbatch_norm_gain, batch_norm_gain)\n",
    "cmp('dbatch_norm_bias', dbatch_norm_bias, batch_norm_bias)\n",
    "cmp('dbnraw', dbnraw, bnraw)\n",
    "cmp('dbnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('dbnvar', dbnvar, bnvar)\n",
    "cmp('dbndiff2', dbndiff2, bndiff2)\n",
    "cmp('dbndiff', dbndiff, bndiff)\n",
    "cmp('dbnmeani', dbnmeani, bnmeani)\n",
    "cmp('dhprebn', dhprebn, hprebn)\n",
    "cmp('dembcat', dembcat, embcat)\n",
    "cmp('dW1', dW1, W1)\n",
    "cmp('db1', db1, b1)\n",
    "cmp('demb', demb, emb)\n",
    "cmp('dC', dC, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"#appendix\">Go to Appendix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<a href=\"#appendix\">Go to Appendix</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss_fast: 3.6580395698547363 diff: 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# backward pass for cross-entropy in one go\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(f\"Loss_fast: {loss_fast} diff: {loss_fast.item() - loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlogits         | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# Before: forward pass for cross-entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes  # subtract max for numerical stability ??\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdim=True)\n",
    "# counts_sum_inv = counts_sum**-1\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# for a single logit example, the derivative of the loss w.r.t the logit example comes out to be the following:\n",
    "# --- softmax of the logit (when the logit's index is not equal to Yb)\n",
    "# --- softmax of the logit - 1 (when the logit's index is equal to Yb)\n",
    "# see appendix for handwritten impl.\n",
    "# need to also scale down the derivative over the average, since the final loss is the average over the losses of all the examples.\n",
    "dlogits = F.softmax(logits, dim=1) # need to do softmax over the rows\n",
    "dlogits[range(logits.shape[0]), Yb] -= 1.0\n",
    "dlogits /= n\n",
    "cmp('dlogits', dlogits, logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0201, 0.0274, 0.0311, 0.0306, 0.0232, 0.0410, 0.0437, 0.1083, 0.0328,\n",
       "        0.0145, 0.0380, 0.0214, 0.0349, 0.0333, 0.0226, 0.0514, 0.0134, 0.0159,\n",
       "        0.0248, 0.1190, 0.0307, 0.0360, 0.0349, 0.0347, 0.0366, 0.0320, 0.0478],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9799,  0.0274,  0.0311,  0.0306,  0.0232,  0.0410,  0.0437,  0.1083,\n",
       "         0.0328,  0.0145,  0.0380,  0.0214,  0.0349,  0.0333,  0.0226,  0.0514,\n",
       "         0.0134,  0.0159,  0.0248,  0.1190,  0.0307,  0.0360,  0.0349,  0.0347,\n",
       "         0.0366,  0.0320,  0.0478], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x73aa367bc800>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: 4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# backprop through batchnorm in one go\n",
    "# IMP: Look at the expression for the output of batchnorm, \n",
    "# take the derivative w.r.t the input, simplify the expression and just write it out\n",
    "\n",
    "# forward pass\n",
    "# Before:\n",
    "# bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = (\n",
    "#     1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    "# )  # Bessel's correction, dividing by (n-1) not n, for mean calc\n",
    "# with torch.no_grad():\n",
    "#     epsilon = 1e-5\n",
    "# bnvar_inv = (bnvar + epsilon) ** -0.5  # inverse of \"bnstd\"\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "\n",
    "# now\n",
    "hpreact_fast = batch_norm_gain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + batch_norm_bias\n",
    "print(f\"diff: {(hpreact_fast - hpreact).abs().max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhprebn         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dhprebn = ((batch_norm_gain * bnvar_inv) / n) * (n * dhpreact - dhpreact.sum(0) - (n / (n - 1)) * bnraw * (dhpreact * bnraw).sum(0))\n",
    "cmp('dhprebn', dhprebn, hprebn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   10000 /  200000: Loss: 2.1858394145965576\n",
      "Step:   20000 /  200000: Loss: 2.2217931747436523\n",
      "Step:   30000 /  200000: Loss: 2.568878173828125\n",
      "Step:   40000 /  200000: Loss: 2.011460781097412\n",
      "Step:   50000 /  200000: Loss: 1.8885668516159058\n",
      "Step:   60000 /  200000: Loss: 2.231832981109619\n",
      "Step:   70000 /  200000: Loss: 1.7523143291473389\n",
      "Step:   80000 /  200000: Loss: 2.202672243118286\n",
      "Step:   90000 /  200000: Loss: 2.3070738315582275\n",
      "Step:  100000 /  200000: Loss: 2.013549566268921\n",
      "Step:  110000 /  200000: Loss: 2.2927892208099365\n",
      "Step:  120000 /  200000: Loss: 1.997328758239746\n",
      "Step:  130000 /  200000: Loss: 2.2945330142974854\n",
      "Step:  140000 /  200000: Loss: 2.011981725692749\n",
      "Step:  150000 /  200000: Loss: 2.0766196250915527\n",
      "Step:  160000 /  200000: Loss: 1.8273742198944092\n",
      "Step:  170000 /  200000: Loss: 2.060242176055908\n",
      "Step:  180000 /  200000: Loss: 2.3239381313323975\n",
      "Step:  190000 /  200000: Loss: 1.911529541015625\n"
     ]
    }
   ],
   "source": [
    "# implement complete training w/o pytorch backward\n",
    "\n",
    "# ---------INIT--------------\n",
    "#IMP FOR THIS NOTEBOOK: CHANGE SOME INIT VALUES AS ZEROS MAY MASK SOME INCORRECT GRADIENT IMPL, **JUST FOR LEARNING PURPOSES**\n",
    "\n",
    "# build MLP\n",
    "\n",
    "# MLP structure params\n",
    "emb_dim_size = 10\n",
    "hidden_layer_size = 64\n",
    "\n",
    "# MLP params\n",
    "C = torch.randn((vocab_size, emb_dim_size), generator=g).float() # represent each character in dim space\n",
    "#Layer 1\n",
    "W1 = torch.randn((block_size * emb_dim_size, hidden_layer_size), generator=g).float() # weights for hidden layer, for each neuron, it will receive block_size number of i/p, each i/p of dimension dim_size\n",
    "W1 = W1 * (5/3) / ((block_size * emb_dim_size) ** 0.5) # kiming_init - to \"fight the contraction of tanh\", preserve gaussian std. -> to resolve tanh saturation\n",
    "b1 = torch.randn(hidden_layer_size, generator=g).float() # each neuron will have 1-D bias # USING BIAS JUST FOR FUN\n",
    "b1 = b1 * 0.1 # normally: 0.001 # to resolve tanh saturation\n",
    "# Layer 2\n",
    "W2 = torch.randn((hidden_layer_size, vocab_size), generator=g).float() # weights for output layer, each neuron of hidden layer fully connected to each neuron of output layer\n",
    "W2 = W2 * 0.1 # to normalize loss at initialization\n",
    "b2 = torch.randn(vocab_size, generator=g).float() # num_neurons in output layer equal to vocab size, to represent probs for each character\n",
    "b2 = b2 * 0.1 # normally 0 # to normalize loss at initialization\n",
    "\n",
    "## batch norm params: want the distribution to be more flexible, not constrict it to be always Gaussian, just need at initialization.\n",
    "# batch_norm_gain = torch.ones((1, hidden_layer_size))\n",
    "# batch_norm_bias = torch.zeros((1, hidden_layer_size))\n",
    "# change from normal, normal above\n",
    "batch_norm_gain = torch.randn((1, hidden_layer_size)) * 0.1 + 1.0\n",
    "batch_norm_bias = torch.randn((1, hidden_layer_size)) * 0.1\n",
    "\n",
    "params = [C, W1, b1, W2, b2, batch_norm_gain, batch_norm_bias]\n",
    "\n",
    "running_mean = torch.zeros((1, hidden_layer_size))\n",
    "running_std = torch.ones((1, hidden_layer_size))\n",
    "\n",
    "print(sum(p.nelement() for p in params))\n",
    "\n",
    "# for p in params:\n",
    "#     p.requires_grad = True # not needed now, as MANUAL MF!!!\n",
    "\n",
    "# stats_init\n",
    "lossi = []\n",
    "\n",
    "#--------FORWARD--------------\n",
    "batch_size = 32\n",
    "n_epochs = 200_000\n",
    "n = batch_size\n",
    "for i in range(n_epochs):\n",
    "    # construct minibatch\n",
    "    with torch.no_grad():\n",
    "        ix = torch.randint(0, X_train.shape[0], (n, ), generator=g)\n",
    "        Xb, Yb = X_train[ix], Y_train[ix]\n",
    "        # FORWARD PASS: CHUNKED INTO SIMPLE, MANAGEABLE STEPS THAT CAN BE BACKPROP'ED ONE AT A TIME\n",
    "\n",
    "        emb = C[Xb]\n",
    "        embcat = emb.view(emb.shape[0], -1)\n",
    "        # -----------Linear layer 1---------------\n",
    "        hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "        # ----------BatchNorm layer---------------\n",
    "        bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "        bndiff = hprebn - bnmeani\n",
    "        bndiff2 = bndiff**2\n",
    "        bnvar = (\n",
    "            1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    "        )  # Bessel's correction, dividing by (n-1) not n, for mean calc\n",
    "        with torch.no_grad():\n",
    "            epsilon = 1e-5\n",
    "        bnvar_inv = (bnvar + epsilon) ** -0.5  # inverse of \"bnstd\"\n",
    "        bnraw = bndiff * bnvar_inv\n",
    "        hpreact = batch_norm_gain * bnraw + batch_norm_bias\n",
    "        # ----------Non-linearity---------------\n",
    "        h = torch.tanh(hpreact)\n",
    "        # Linear layer 2\n",
    "        logits = h @ W2 + b2\n",
    "        # cross-entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "        logit_maxes = logits.max(1, keepdim=True).values\n",
    "        norm_logits = logits - logit_maxes  # subtract max for numerical stability ??\n",
    "        counts = norm_logits.exp()\n",
    "        counts_sum = counts.sum(1, keepdim=True)\n",
    "        counts_sum_inv = counts_sum**-1\n",
    "        probs = counts * counts_sum_inv\n",
    "        logprobs = probs.log()\n",
    "        loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "        # Pytorch backward pass\n",
    "        for p in params:\n",
    "            p.grad = None\n",
    "\n",
    "\n",
    "        gradvars = [\n",
    "            logprobs,\n",
    "            probs,\n",
    "            counts,\n",
    "            counts_sum,\n",
    "            counts_sum_inv,\n",
    "            norm_logits,\n",
    "            logit_maxes,\n",
    "            logits,\n",
    "            h,\n",
    "            hpreact,\n",
    "            bnraw,\n",
    "            bnvar_inv,\n",
    "            bnvar,\n",
    "            bndiff2,\n",
    "            bndiff,\n",
    "            hprebn,\n",
    "            bnmeani,\n",
    "            embcat,\n",
    "            emb\n",
    "        ]\n",
    "\n",
    "        # for t in gradvars:\n",
    "        #     t.retain_grad() # not needed now, as MANUAL MF!!!\n",
    "\n",
    "        # loss.backward() # not needed now, as MANUAL MF!!!\n",
    "\n",
    "        #--------BACKWARD: MANUAL :)--------------\n",
    "        dlogprobs = torch.zeros_like(logprobs)\n",
    "        dlogprobs[range(n), Yb] = -1.0/n\n",
    "        dprobs = 1.0/probs\n",
    "        dprobs = dprobs * dlogprobs\n",
    "        dcounts_sum_inv = counts\n",
    "        dcounts_sum_inv = dcounts_sum_inv * dprobs\n",
    "        dcounts_sum_inv = dcounts_sum_inv.sum(1, keepdim=True)\n",
    "        dcounts = counts_sum_inv\n",
    "        dcounts = dcounts * dprobs\n",
    "        dcounts_sum = (-counts_sum ** -2)\n",
    "        dcounts_sum = dcounts_sum * dcounts_sum_inv\n",
    "        dcounts = dcounts + (torch.ones(counts.shape) * dcounts_sum)\n",
    "        dnorm_logits = counts * dcounts\n",
    "        dlogit_maxes = -(torch.ones_like(logit_maxes) * dnorm_logits).sum(1, keepdim=True)\n",
    "        dlogits = torch.ones_like(logits) * dnorm_logits\n",
    "        dlogits = dlogits + ((logits == logit_maxes).float()) * dlogit_maxes\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = (dlogits.T @ h).T\n",
    "        db2 = dlogits.sum(0)\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        dbatch_norm_gain = (bnraw * dhpreact).sum(0)\n",
    "        dbatch_norm_bias = dhpreact.sum(0)\n",
    "        dbnraw = batch_norm_gain * dhpreact\n",
    "        dbndiff = bnvar_inv * dbnraw\n",
    "        dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "        dbnvar = (-0.5 * bnvar_inv ** 3) * dbnvar_inv\n",
    "        dbndiff2 = ((1.0 / (n - 1)) * torch.ones_like(bndiff2)) * dbnvar\n",
    "        dbndiff += ((2.0 * bndiff) * dbndiff2)\n",
    "        dhprebn = dbndiff.clone()\n",
    "        dbnmeani = (-1.0 * dbndiff).sum(0, keepdim=True)\n",
    "        dhprebn += ((1.0 / n) * torch.ones_like(hprebn)) * dbnmeani\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        demb = dembcat.view_as(emb)\n",
    "        dC = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k, j]\n",
    "                dC[ix] += demb[k, j]\n",
    "        \n",
    "        grads = [dC, dW1, db1, dW2, db2, dbatch_norm_gain, dbatch_norm_bias]\n",
    "\n",
    "        #--------UPDATE--------------\n",
    "        lr = 10 ** -1 if i < 100_000 else 10 ** -2\n",
    "        for p, grad in zip(params, grads):\n",
    "            # p.data += -lr * p.grad # old way\n",
    "            p.data += -lr * grad\n",
    "        \n",
    "        # track_stats\n",
    "        if i and i % 10_000 == 0:\n",
    "            print(f\"Step: {i:7d} / {n_epochs:7d}: Loss: {loss.item()}\")\n",
    "            lossi.append(loss.log10().item())\n",
    "        \n",
    "        # # early breaking (for debug purposes)\n",
    "        # if i > 100:\n",
    "        #     break\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate batch_norm at the end of the training\n",
    "with torch.no_grad():\n",
    "    emb = C[X_train]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 2.1465587615966797\n",
      "val loss = 2.1739919185638428\n",
      "test loss = 2.1772708892822266\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()  # decorator prevents gradient tracking\n",
    "def split_loss(split: str):\n",
    "    x, y = {\n",
    "        \"train\": (X_train, Y_train),\n",
    "        \"val\": (X_val, Y_val),\n",
    "        \"test\": (X_test, Y_test),\n",
    "    }[split]\n",
    "\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    \n",
    "    hpreact = batch_norm_gain * (hpreact - bnmean) * (bnvar + 1e-5) ** -0.5 + batch_norm_bias\n",
    "\n",
    "    h = torch.tanh(hpreact)\n",
    "\n",
    "    logits = h @ W2 + b2\n",
    "\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "\n",
    "    print(f\"{split} loss = {loss.item()}\")\n",
    "\n",
    "split_loss(\"train\")\n",
    "split_loss(\"val\")\n",
    "split_loss(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gavir.\n",
      "holdengni.\n",
      "jozeliy.\n",
      "lun.\n",
      "baiyah.\n",
      "begamilyanihilius.\n",
      "keny.\n",
      "domatee.\n",
      "blaix.\n",
      "hilyn.\n",
      "paenaneel.\n",
      "led.\n",
      "patticoniel.\n",
      "frulli.\n",
      "zymaniba.\n",
      "ogi.\n",
      "maki.\n",
      "sumilliereley.\n",
      "sun.\n",
      "everiananlegan.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2641/2461408105.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "\n",
    "def sample(num_samples: int = 20):\n",
    "    for _ in range(num_samples):\n",
    "        samples = []\n",
    "        context = [0] * block_size # init with all ...\n",
    "        while True:\n",
    "            # forward pass the neural net\n",
    "            emb = C[torch.tensor([context])]\n",
    "            embcat = emb.view(emb.shape[0], block_size * emb_dim_size)\n",
    "            hpreact = embcat @ W1 + b1\n",
    "    \n",
    "            hpreact = batch_norm_gain * (hpreact - bnmean) * (bnvar + 1e-5) ** -0.5 + batch_norm_bias\n",
    "\n",
    "            h = torch.tanh(hpreact)\n",
    "\n",
    "            logits = h @ W2 + b2\n",
    "            probs = F.softmax(logits)\n",
    "            # sample from the distribution\n",
    "            ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "            context = context[1:] + [ix]\n",
    "            samples.append(ix)\n",
    "            if ix == 0:\n",
    "                break\n",
    "        \n",
    "        print(''.join(itos[i] for i in samples))\n",
    "\n",
    "sample()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "Appendix"
    ]
   },
   "source": [
    "# Appendix\n",
    "## Matmul Backprop Calculation\n",
    "![Matmul Backprop Steps](assets/matmul_backprop/IMG_20250131_191121501_HDR.jpg)\n",
    "### (Continued)\n",
    "![Matmul Backprop Steps (contd.)](assets/matmul_backprop/IMG_20250131_191127782_HDR.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
